import os
import boto3
from langchain_community.document_loaders import S3DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_aws import BedrockEmbeddings, BedrockLLM
from langchain_community.vectorstores import Chroma
from langchain.indexes import VectorstoreIndexCreator
import warnings
import contextlib
import sys
import io

BUCKET_NAME = "juridicosprojeto4"
PREFIX = "juridicos/"
CHROMA_PERSIST_DIR = "/tmp/chroma_db"

# VariÃ¡vel global para cache do Ã­ndice
cached_index = None

def silent_load(loader):
    buffer = io.StringIO()
    with contextlib.redirect_stdout(buffer), contextlib.redirect_stderr(buffer):
        return loader.load()

# === CriaÃ§Ã£o do Ã­ndice vetorial (com cache) ===
def hr_index():
    global cached_index
    
    if cached_index is not None:
        print("âœ… Retornando Ã­ndice do cache")
        return cached_index
    
    try:
        # Verifica se jÃ¡ existe ChromaDB persistido
        if os.path.exists(CHROMA_PERSIST_DIR) and os.listdir(CHROMA_PERSIST_DIR):
            print("ðŸ“‚ Carregando Ã­ndice persistido do ChromaDB...")
            embeddings = BedrockEmbeddings(
                region_name="us-east-1",
                model_id="amazon.titan-embed-text-v1"
            )
            
            vectorstore = Chroma(
                persist_directory=CHROMA_PERSIST_DIR,
                embedding_function=embeddings
            )
            
            cached_index = VectorstoreIndexCreator(
                vectorstore=vectorstore
            ).from_vectorstore(vectorstore)
            
            return cached_index

        print("ðŸ†• Criando novo Ã­ndice vetorial...")
        
        session = boto3.Session()
        s3 = session.client("s3")
        s3.head_bucket(Bucket=BUCKET_NAME)
        print("âœ… ConexÃ£o com S3 validada")

        loader = S3DirectoryLoader(bucket=BUCKET_NAME, prefix=PREFIX)
        documents = silent_load(loader)
        print(f"ðŸ“„ Total de documentos carregados: {len(documents)}")

        if not documents:
            raise RuntimeError("Nenhum documento encontrado no S3.")

        # Quebra documentos em pedaÃ§os
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )

        embeddings = BedrockEmbeddings(
            region_name="us-east-1",
            model_id="amazon.titan-embed-text-v1"
        )

        index_creator = VectorstoreIndexCreator(
            text_splitter=text_splitter,
            embedding=embeddings,
            vectorstore_cls=Chroma,
            vectorstore_kwargs={
                "persist_directory": CHROMA_PERSIST_DIR
            }
        )

        print("ðŸ”Ž Criando e persistindo Ã­ndice vetorial...")
        cached_index = index_creator.from_documents(documents)
        
        cached_index.vectorstore.persist()
        
        return cached_index

    except Exception as e:
        print(f"ðŸ’¥ Erro: {str(e)}")
        raise

def hr_llm():
    return BedrockLLM(
        model_id="amazon.titan-text-premier-v1:0",
        region_name="us-east-1",
        model_kwargs={
            "temperature": 0.3,
            "maxTokenCount": 2048
        }
    )

def hr_rag_response(index, question: str):
    rag_llm = hr_llm()
    return index.query(question=question, llm=rag_llm)